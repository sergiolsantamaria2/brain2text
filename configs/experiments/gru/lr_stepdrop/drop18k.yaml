num_training_batches: 20000

lr_scheduler_type: cosine_stepdrop
lr_stepdrop_step: 18000
lr_stepdrop_factor: 0.1

lr_decay_steps: ${num_training_batches}
lr_decay_steps_day: ${num_training_batches}

output_dir: trained_models/lr_stepdrop/drop18k
checkpoint_dir: ${output_dir}/checkpoint

save_all_val_steps: false
save_val_logits: false
save_final_model: false
save_best_checkpoint: true

wandb:
  enabled: true
  group: lr_stepdrop
  run_name: drop18k
  tags: ["lr_stepdrop", "cosine", "drop@18k", "factor0.1", "T=20k"]
