# Diphone + Speckle masking
# Combines two proven improvements:
# - Diphones (DCoND): PER 16.62% -> 15.34%
# - Speckle masking (4th place): additional regularization

num_training_batches: 20000

use_diphones: true

model:
  decoder_type: gru
  n_units: 768
  n_layers: 5
  rnn_dropout: 0.2
  
  patch_size: 14
  patch_stride: 4
  
  head_type: "none"
  head_num_blocks: 0
  
  # Add speckle masking (your optimal value)
  input_speckle_p: 0.10
  input_speckle_mode: "feature"

lr_scheduler_type: cosine
lr_max: 0.003
lr_min: 0.0001
lr_decay_steps: ${num_training_batches}
lr_warmup_steps: 500

lr_max_day: 0.001
lr_min_day: 0.0001
lr_decay_steps_day: ${num_training_batches}
lr_warmup_steps_day: 500

weight_decay: 0.00001

output_dir: trained_models/diphones/diphone_speckle
checkpoint_dir: ${output_dir}/checkpoint

wandb:
  enabled: true
  group: diphones
  run_name: diphone_speckle
  tags: ["diphones", "dcond", "gru", "speckle"]

save_val_logits: false
